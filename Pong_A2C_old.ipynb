{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMtwRvzULsvO75jGQh6kML0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Helena26-ai/Rainforcement_project/blob/Antek/Pong_A2C_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl_kBQJO5g5Y",
        "outputId": "f46dfe98-ae3f-4d7c-9d79-c8952ad3a022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchrl\n",
        "!pip install gymnasium[atari,accept-rom-license]==0.29.1\n",
        "!pip install opencv-python-headless tensorboard moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H4FVR9w5lC6",
        "outputId": "6e985a9e-92c6-4bca-a2f9-c272a868a5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.8.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Collecting tensordict<0.9.0,>=0.8.3 (from torchrl)\n",
            "  Downloading tensordict-0.8.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.3->torchrl) (8.7.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.3->torchrl) (3.10.18)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict<0.9.0,>=0.8.3->torchrl) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->torchrl) (3.0.2)\n",
            "Downloading torchrl-0.8.1-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.8.3-cp311-cp311-manylinux_2_28_x86_64.whl (420 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.7/420.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensordict, torchrl\n",
            "Successfully installed tensordict-0.8.3 torchrl-0.8.1\n",
            "Collecting gymnasium==0.29.1 (from gymnasium[accept-rom-license,atari]==0.29.1)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (0.0.4)\n",
            "Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1)\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1)\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (8.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (4.67.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1)\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1) (6.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2025.4.26)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446710 sha256=63deedc636483b5406b75ae32db02cb713b735770c42163b91fecfd81245c478\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: gymnasium, ale-py, shimmy, AutoROM.accept-rom-license, autorom\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.11.0\n",
            "    Uninstalling ale-py-0.11.0:\n",
            "      Successfully uninstalled ale-py-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 gymnasium-0.29.1 shimmy-0.2.1\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sprawdzenie, czy środowisko Pong jest dostępne\n",
        "import gymnasium as gym\n",
        "env = gym.make(\"PongNoFrameskip-v4\", render_mode=\"rgb_array\")\n",
        "print(\"Środowisko załadowane poprawnie:\", env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE45vC-W5pb5",
        "outputId": "db614806-7138-4830-f8d7-9cf9e07380db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Środowisko załadowane poprawnie: <OrderEnforcing<PassiveEnvChecker<AtariEnv<PongNoFrameskip-v4>>>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install ptan==0.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBAJCkRu5rZE",
        "outputId": "7dff61b4-e076-4597-86a7-88b5095ce661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting ptan==0.8.1\n",
            "  Downloading ptan-0.8.1-py3-none-any.whl.metadata (521 bytes)\n",
            "Requirement already satisfied: gymnasium>=0.29.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]>=0.29.0->ptan==0.8.1) (0.29.1)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.11/dist-packages (from ptan==0.8.1) (1.0.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from ptan==0.8.1) (1.26.4)\n",
            "Collecting opencv-python==4.10.0.84 (from ptan==0.8.1)\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting torch==2.5.0 (from ptan==0.8.1)\n",
            "  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.20.0 (from ptan==0.8.1)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pytorch-ignite==0.5.1 (from ptan==0.8.1)\n",
            "  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting stable-baselines3==2.3.2 (from ptan==0.8.1)\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan==0.8.1) (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite==0.5.1->ptan==0.8.1) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2->ptan==0.8.1) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2->ptan==0.8.1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2->ptan==0.8.1) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (12.4.127)\n",
            "Collecting triton==3.1.0 (from torch==2.5.0->ptan==0.8.1)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->ptan==0.8.1) (1.13.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0->ptan==0.8.1) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0->ptan==0.8.1) (1.3.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.29.0->gymnasium[atari]>=0.29.0->ptan==0.8.1) (0.0.4)\n",
            "Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan==0.8.1) (0.2.1)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]>=0.29.0->ptan==0.8.1) (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan==0.8.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan==0.8.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan==0.8.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan==0.8.1) (2025.4.26)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.11/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan==0.8.1) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0->ptan==0.8.1) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.3.2->ptan==0.8.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.3.2->ptan==0.8.1) (2025.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan==0.8.1) (6.5.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.3.2->ptan==0.8.1) (1.17.0)\n",
            "Downloading ptan-0.8.1-py3-none-any.whl (26 kB)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, opencv-python, torch, torchvision, stable-baselines3, pytorch-ignite, ptan\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-4.10.0.84 ptan-0.8.1 pytorch-ignite-0.5.1 stable-baselines3-2.3.2 torch-2.5.0 torchvision-0.20.0 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              },
              "id": "8379cb2fc96e4d1194cfac5e3febbbb8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import typing as tt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from ptan.experience import ExperienceFirstLast\n",
        "\n",
        "class RewardTracker:\n",
        "    def __init__(self, writer, stop_reward):\n",
        "        self.writer = writer\n",
        "        self.stop_reward = stop_reward\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.ts = time.time()\n",
        "        self.ts_frame = 0\n",
        "        self.total_rewards = []\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.writer.close()\n",
        "\n",
        "    def reward(self, reward, frame):\n",
        "        self.total_rewards.append(reward)\n",
        "        speed = (frame - self.ts_frame) / (time.time() - self.ts)\n",
        "        self.ts_frame = frame\n",
        "        self.ts = time.time()\n",
        "        mean_reward = np.mean(self.total_rewards[-100:])\n",
        "        print(f\"{frame}: done {len(self.total_rewards)} games, mean reward {mean_reward:.3f}, speed {speed:.2f} f/s\")\n",
        "        self.writer.add_scalar(\"reward_100\", mean_reward, frame)\n",
        "        self.writer.add_scalar(\"reward\", reward, frame)\n",
        "        self.writer.add_scalar(\"speed\", speed, frame)\n",
        "        if mean_reward > self.stop_reward:\n",
        "            print(f\"Solved in {frame} frames!\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "class AtariA2C(nn.Module):\n",
        "    def __init__(self, input_shape: tt.Tuple[int, ...], n_actions: int):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
        "        self.policy = nn.Sequential(nn.Linear(size, 512), nn.ReLU(), nn.Linear(512, n_actions))\n",
        "        self.value = nn.Sequential(nn.Linear(size, 512), nn.ReLU(), nn.Linear(512, 1))\n",
        "\n",
        "    def forward(self, x: torch.ByteTensor) -> tt.Tuple[torch.Tensor, torch.Tensor]:\n",
        "        xx = x.float() / 255.0\n",
        "        conv_out = self.conv(xx)\n",
        "        return self.policy(conv_out), self.value(conv_out)\n",
        "\n",
        "def unpack_batch(batch, net, device, gamma, reward_steps):\n",
        "    states, actions, rewards, not_done_idx, last_states = [], [], [], [], []\n",
        "    for idx, exp in enumerate(batch):\n",
        "        states.append(np.asarray(exp.state))\n",
        "        actions.append(int(exp.action))\n",
        "        rewards.append(exp.reward)\n",
        "        if exp.last_state is not None:\n",
        "            not_done_idx.append(idx)\n",
        "            last_states.append(np.asarray(exp.last_state))\n",
        "\n",
        "    states_t = torch.FloatTensor(np.array(states)).to(device)\n",
        "    actions_t = torch.LongTensor(actions).to(device)\n",
        "    rewards_np = np.array(rewards, dtype=np.float32)\n",
        "    if not_done_idx:\n",
        "        last_states_t = torch.FloatTensor(np.array(last_states)).to(device)\n",
        "        last_vals_t = net(last_states_t)[1]\n",
        "        rewards_np[not_done_idx] += (gamma ** reward_steps) * last_vals_t.data.cpu().numpy()[:, 0]\n",
        "    ref_vals_t = torch.FloatTensor(rewards_np).to(device)\n",
        "    return states_t, actions_t, ref_vals_t"
      ],
      "metadata": {
        "id": "KTdewPAaqz_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e4bdfd-ce46-4dc3-c04a-de3adbe31524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ptan\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils as nn_utils\n",
        "import ale_py\n",
        "import gymnasium as gym\n",
        "\n",
        "GAMMA = 0.99\n",
        "LEARNING_RATE = 0.001\n",
        "ENTROPY_BETA = 0.01\n",
        "BATCH_SIZE = 128\n",
        "REWARD_STEPS = 4\n",
        "CLIP_GRAD = 0.1\n",
        "NUM_ENVS = 50  # Google Colab ogranicza zasoby, nieprawda!\n",
        "\n",
        "from ptan.experience import VectorExperienceSourceFirstLast\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "env_fns = [lambda: ptan.common.wrappers.wrap_dqn(gym.make(\"PongNoFrameskip-v4\")) for _ in range(NUM_ENVS)]\n",
        "env = gym.vector.SyncVectorEnv(env_fns)\n",
        "writer = SummaryWriter(comment=\"-pong-a2c-colab\")\n",
        "\n",
        "net = AtariA2C(env.single_observation_space.shape, env.single_action_space.n).to(device)\n",
        "agent = ptan.agent.PolicyAgent(lambda x: net(x)[0], apply_softmax=True, device=device)\n",
        "exp_source = VectorExperienceSourceFirstLast(env, agent, gamma=GAMMA, steps_count=REWARD_STEPS)\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)\n",
        "\n",
        "best_reward = -float('inf')\n",
        "batch = []\n",
        "\n",
        "with RewardTracker(writer, stop_reward=18) as tracker:\n",
        "    for step_idx, exp in enumerate(exp_source):\n",
        "        batch.append(exp)\n",
        "        for reward in exp_source.pop_total_rewards():\n",
        "            if tracker.reward(reward, step_idx):\n",
        "                torch.save(net.state_dict(), \"best_model.pth\")\n",
        "                break\n",
        "            if reward > best_reward:\n",
        "                best_reward = reward\n",
        "                torch.save(net.state_dict(), \"best_model.pth\")\n",
        "\n",
        "        if len(batch) < BATCH_SIZE:\n",
        "            continue\n",
        "\n",
        "        states_t, actions_t, vals_ref_t = unpack_batch(batch, net, device, GAMMA, REWARD_STEPS)\n",
        "        batch.clear()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits_t, value_t = net(states_t)\n",
        "        loss_value = F.mse_loss(value_t.squeeze(-1), vals_ref_t)\n",
        "\n",
        "        log_prob = F.log_softmax(logits_t, dim=1)\n",
        "        adv = vals_ref_t - value_t.detach()\n",
        "        log_act = log_prob[range(BATCH_SIZE), actions_t]\n",
        "        loss_policy = -(adv * log_act).mean()\n",
        "\n",
        "        prob = F.softmax(logits_t, dim=1)\n",
        "        entropy_loss = ENTROPY_BETA * (prob * log_prob).sum(dim=1).mean()\n",
        "\n",
        "        loss = entropy_loss + loss_value + loss_policy\n",
        "        loss.backward()\n",
        "        nn_utils.clip_grad_norm_(net.parameters(), CLIP_GRAD)\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmxXNwY2q3i-",
        "outputId": "81023dc2-d6e4-491c-ed28-69736f593853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37850: done 1 games, mean reward -21.000, speed 747.82 f/s\n",
            "37850: done 2 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 3 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 4 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 5 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 6 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 7 games, mean reward -21.000, speed 0.00 f/s\n",
            "37850: done 8 games, mean reward -21.000, speed 0.00 f/s\n",
            "38800: done 9 games, mean reward -21.000, speed 758.96 f/s\n",
            "39250: done 10 games, mean reward -21.000, speed 692.91 f/s\n",
            "39250: done 11 games, mean reward -21.000, speed 0.00 f/s\n",
            "39250: done 12 games, mean reward -21.000, speed 0.00 f/s\n",
            "39250: done 13 games, mean reward -21.000, speed 0.00 f/s\n",
            "39250: done 14 games, mean reward -21.000, speed 0.00 f/s\n",
            "39250: done 15 games, mean reward -21.000, speed 0.00 f/s\n",
            "39300: done 16 games, mean reward -21.000, speed 564.18 f/s\n",
            "40200: done 17 games, mean reward -21.000, speed 761.73 f/s\n",
            "40250: done 18 games, mean reward -21.000, speed 733.27 f/s\n",
            "40650: done 19 games, mean reward -21.000, speed 755.54 f/s\n",
            "40700: done 20 games, mean reward -21.000, speed 730.23 f/s\n",
            "40750: done 21 games, mean reward -21.000, speed 594.54 f/s\n",
            "40850: done 22 games, mean reward -21.000, speed 600.17 f/s\n",
            "40850: done 23 games, mean reward -21.000, speed 0.00 f/s\n",
            "40850: done 24 games, mean reward -21.000, speed 0.00 f/s\n",
            "40950: done 25 games, mean reward -21.000, speed 794.90 f/s\n",
            "41850: done 26 games, mean reward -20.962, speed 774.38 f/s\n",
            "42150: done 27 games, mean reward -20.963, speed 681.36 f/s\n",
            "42150: done 28 games, mean reward -20.964, speed 0.00 f/s\n",
            "42250: done 29 games, mean reward -20.966, speed 641.66 f/s\n",
            "42250: done 30 games, mean reward -20.967, speed 0.00 f/s\n",
            "42300: done 31 games, mean reward -20.968, speed 724.07 f/s\n",
            "42400: done 32 games, mean reward -20.969, speed 709.17 f/s\n",
            "42700: done 33 games, mean reward -20.939, speed 754.86 f/s\n",
            "43250: done 34 games, mean reward -20.941, speed 764.70 f/s\n",
            "43700: done 35 games, mean reward -20.943, speed 746.74 f/s\n",
            "43900: done 36 games, mean reward -20.944, speed 764.25 f/s\n",
            "43950: done 37 games, mean reward -20.946, speed 584.62 f/s\n",
            "44400: done 38 games, mean reward -20.921, speed 765.25 f/s\n",
            "44550: done 39 games, mean reward -20.897, speed 692.24 f/s\n",
            "46150: done 40 games, mean reward -20.875, speed 774.01 f/s\n",
            "47700: done 41 games, mean reward -20.854, speed 768.81 f/s\n",
            "47800: done 42 games, mean reward -20.833, speed 693.72 f/s\n",
            "48900: done 43 games, mean reward -20.814, speed 754.07 f/s\n",
            "49400: done 44 games, mean reward -20.773, speed 784.87 f/s\n",
            "49500: done 45 games, mean reward -20.733, speed 595.16 f/s\n",
            "53600: done 46 games, mean reward -20.739, speed 775.45 f/s\n",
            "55050: done 47 games, mean reward -20.681, speed 768.11 f/s\n",
            "55500: done 48 games, mean reward -20.646, speed 740.70 f/s\n",
            "56950: done 49 games, mean reward -20.612, speed 771.58 f/s\n",
            "57400: done 50 games, mean reward -20.560, speed 745.77 f/s\n",
            "77350: done 51 games, mean reward -20.569, speed 776.31 f/s\n",
            "78300: done 52 games, mean reward -20.577, speed 776.19 f/s\n",
            "78350: done 53 games, mean reward -20.585, speed 577.18 f/s\n",
            "78950: done 54 games, mean reward -20.593, speed 769.00 f/s\n",
            "78950: done 55 games, mean reward -20.600, speed 0.00 f/s\n",
            "79950: done 56 games, mean reward -20.607, speed 760.68 f/s\n",
            "80000: done 57 games, mean reward -20.614, speed 588.26 f/s\n",
            "81350: done 58 games, mean reward -20.603, speed 777.49 f/s\n",
            "81750: done 59 games, mean reward -20.610, speed 766.13 f/s\n",
            "81800: done 60 games, mean reward -20.617, speed 578.37 f/s\n",
            "82700: done 61 games, mean reward -20.607, speed 755.89 f/s\n",
            "82750: done 62 games, mean reward -20.597, speed 682.44 f/s\n",
            "82900: done 63 games, mean reward -20.603, speed 717.02 f/s\n",
            "83350: done 64 games, mean reward -20.609, speed 745.62 f/s\n",
            "83800: done 65 games, mean reward -20.600, speed 754.94 f/s\n",
            "84000: done 66 games, mean reward -20.606, speed 699.86 f/s\n",
            "84350: done 67 games, mean reward -20.597, speed 760.73 f/s\n",
            "84450: done 68 games, mean reward -20.588, speed 693.12 f/s\n",
            "84800: done 69 games, mean reward -20.580, speed 742.39 f/s\n",
            "85050: done 70 games, mean reward -20.586, speed 738.43 f/s\n",
            "85100: done 71 games, mean reward -20.577, speed 705.43 f/s\n",
            "85650: done 72 games, mean reward -20.569, speed 742.13 f/s\n",
            "85700: done 73 games, mean reward -20.562, speed 711.72 f/s\n",
            "85750: done 74 games, mean reward -20.554, speed 711.32 f/s\n",
            "85850: done 75 games, mean reward -20.560, speed 675.04 f/s\n",
            "85950: done 76 games, mean reward -20.553, speed 694.40 f/s\n",
            "86450: done 77 games, mean reward -20.558, speed 751.27 f/s\n",
            "86600: done 78 games, mean reward -20.551, speed 729.74 f/s\n",
            "87600: done 79 games, mean reward -20.557, speed 753.96 f/s\n",
            "87600: done 80 games, mean reward -20.562, speed 0.00 f/s\n",
            "88250: done 81 games, mean reward -20.568, speed 761.47 f/s\n",
            "88650: done 82 games, mean reward -20.573, speed 738.94 f/s\n",
            "88650: done 83 games, mean reward -20.578, speed 0.00 f/s\n",
            "89150: done 84 games, mean reward -20.571, speed 743.67 f/s\n",
            "89450: done 85 games, mean reward -20.576, speed 748.72 f/s\n",
            "91550: done 86 games, mean reward -20.570, speed 757.01 f/s\n",
            "91800: done 87 games, mean reward -20.563, speed 730.57 f/s\n",
            "92100: done 88 games, mean reward -20.557, speed 742.50 f/s\n",
            "94400: done 89 games, mean reward -20.551, speed 759.95 f/s\n",
            "94550: done 90 games, mean reward -20.544, speed 734.10 f/s\n",
            "94750: done 91 games, mean reward -20.549, speed 712.22 f/s\n",
            "95000: done 92 games, mean reward -20.554, speed 740.56 f/s\n",
            "96100: done 93 games, mean reward -20.559, speed 779.92 f/s\n",
            "96650: done 94 games, mean reward -20.553, speed 741.38 f/s\n",
            "97850: done 95 games, mean reward -20.558, speed 772.31 f/s\n",
            "99200: done 96 games, mean reward -20.562, speed 762.34 f/s\n",
            "100900: done 97 games, mean reward -20.557, speed 765.25 f/s\n",
            "103900: done 98 games, mean reward -20.541, speed 774.29 f/s\n",
            "105200: done 99 games, mean reward -20.525, speed 769.13 f/s\n",
            "107550: done 100 games, mean reward -20.520, speed 763.58 f/s\n",
            "118050: done 101 games, mean reward -20.520, speed 770.16 f/s\n",
            "120950: done 102 games, mean reward -20.520, speed 771.75 f/s\n",
            "121000: done 103 games, mean reward -20.520, speed 589.75 f/s\n",
            "121200: done 104 games, mean reward -20.520, speed 769.51 f/s\n",
            "121300: done 105 games, mean reward -20.520, speed 699.04 f/s\n",
            "123950: done 106 games, mean reward -20.520, speed 771.75 f/s\n",
            "124550: done 107 games, mean reward -20.520, speed 759.39 f/s\n",
            "124650: done 108 games, mean reward -20.510, speed 778.43 f/s\n",
            "125200: done 109 games, mean reward -20.510, speed 752.01 f/s\n",
            "126300: done 110 games, mean reward -20.510, speed 769.16 f/s\n",
            "126800: done 111 games, mean reward -20.510, speed 752.64 f/s\n",
            "126950: done 112 games, mean reward -20.500, speed 736.51 f/s\n",
            "127250: done 113 games, mean reward -20.500, speed 727.13 f/s\n",
            "127450: done 114 games, mean reward -20.500, speed 769.07 f/s\n",
            "127800: done 115 games, mean reward -20.500, speed 748.95 f/s\n",
            "128500: done 116 games, mean reward -20.500, speed 769.79 f/s\n",
            "129250: done 117 games, mean reward -20.500, speed 761.35 f/s\n",
            "130150: done 118 games, mean reward -20.490, speed 771.56 f/s\n",
            "130200: done 119 games, mean reward -20.490, speed 591.47 f/s\n",
            "130800: done 120 games, mean reward -20.470, speed 774.03 f/s\n",
            "131050: done 121 games, mean reward -20.470, speed 734.30 f/s\n",
            "131150: done 122 games, mean reward -20.470, speed 644.10 f/s\n",
            "131150: done 123 games, mean reward -20.470, speed 0.00 f/s\n",
            "131250: done 124 games, mean reward -20.470, speed 692.88 f/s\n",
            "131550: done 125 games, mean reward -20.450, speed 767.85 f/s\n",
            "131600: done 126 games, mean reward -20.460, speed 579.74 f/s\n",
            "131950: done 127 games, mean reward -20.460, speed 777.39 f/s\n",
            "133700: done 128 games, mean reward -20.460, speed 771.19 f/s\n",
            "134000: done 129 games, mean reward -20.440, speed 770.14 f/s\n",
            "134200: done 130 games, mean reward -20.440, speed 725.01 f/s\n",
            "134250: done 131 games, mean reward -20.440, speed 731.58 f/s\n",
            "134750: done 132 games, mean reward -20.440, speed 764.82 f/s\n",
            "134850: done 133 games, mean reward -20.450, speed 688.22 f/s\n",
            "134900: done 134 games, mean reward -20.430, speed 686.09 f/s\n",
            "134950: done 135 games, mean reward -20.420, speed 584.43 f/s\n",
            "135300: done 136 games, mean reward -20.410, speed 739.76 f/s\n",
            "135450: done 137 games, mean reward -20.410, speed 749.04 f/s\n",
            "135950: done 138 games, mean reward -20.420, speed 734.52 f/s\n",
            "136800: done 139 games, mean reward -20.420, speed 781.88 f/s\n",
            "137200: done 140 games, mean reward -20.430, speed 758.53 f/s\n",
            "137750: done 141 games, mean reward -20.410, speed 754.13 f/s\n",
            "139100: done 142 games, mean reward -20.420, speed 778.47 f/s\n",
            "139300: done 143 games, mean reward -20.420, speed 729.14 f/s\n",
            "145000: done 144 games, mean reward -20.440, speed 775.01 f/s\n",
            "145100: done 145 games, mean reward -20.460, speed 699.36 f/s\n",
            "147550: done 146 games, mean reward -20.460, speed 776.74 f/s\n",
            "148200: done 147 games, mean reward -20.490, speed 764.18 f/s\n",
            "151200: done 148 games, mean reward -20.490, speed 771.76 f/s\n",
            "155400: done 149 games, mean reward -20.500, speed 769.08 f/s\n",
            "157050: done 150 games, mean reward -20.500, speed 774.95 f/s\n",
            "162050: done 151 games, mean reward -20.500, speed 770.47 f/s\n",
            "162400: done 152 games, mean reward -20.500, speed 763.17 f/s\n",
            "165850: done 153 games, mean reward -20.500, speed 773.09 f/s\n",
            "166050: done 154 games, mean reward -20.490, speed 716.85 f/s\n",
            "166400: done 155 games, mean reward -20.490, speed 747.64 f/s\n",
            "168050: done 156 games, mean reward -20.490, speed 776.44 f/s\n",
            "169550: done 157 games, mean reward -20.490, speed 770.94 f/s\n",
            "170500: done 158 games, mean reward -20.490, speed 754.88 f/s\n",
            "171000: done 159 games, mean reward -20.490, speed 763.64 f/s\n",
            "171550: done 160 games, mean reward -20.490, speed 747.28 f/s\n",
            "171950: done 161 games, mean reward -20.500, speed 761.82 f/s\n",
            "172150: done 162 games, mean reward -20.510, speed 769.74 f/s\n",
            "172450: done 163 games, mean reward -20.510, speed 740.83 f/s\n",
            "172700: done 164 games, mean reward -20.500, speed 751.30 f/s\n",
            "173300: done 165 games, mean reward -20.510, speed 775.32 f/s\n",
            "173350: done 166 games, mean reward -20.510, speed 590.23 f/s\n",
            "174500: done 167 games, mean reward -20.510, speed 768.93 f/s\n",
            "174950: done 168 games, mean reward -20.520, speed 756.23 f/s\n",
            "175100: done 169 games, mean reward -20.530, speed 728.50 f/s\n",
            "176150: done 170 games, mean reward -20.530, speed 763.95 f/s\n",
            "176550: done 171 games, mean reward -20.540, speed 767.94 f/s\n",
            "177000: done 172 games, mean reward -20.550, speed 764.34 f/s\n",
            "177100: done 173 games, mean reward -20.550, speed 687.24 f/s\n",
            "179200: done 174 games, mean reward -20.560, speed 767.56 f/s\n",
            "179250: done 175 games, mean reward -20.550, speed 707.61 f/s\n",
            "179300: done 176 games, mean reward -20.550, speed 721.53 f/s\n",
            "179650: done 177 games, mean reward -20.540, speed 739.77 f/s\n",
            "180400: done 178 games, mean reward -20.550, speed 764.04 f/s\n",
            "182350: done 179 games, mean reward -20.540, speed 768.96 f/s\n",
            "182350: done 180 games, mean reward -20.530, speed 0.00 f/s\n",
            "182650: done 181 games, mean reward -20.520, speed 766.76 f/s\n",
            "182750: done 182 games, mean reward -20.510, speed 642.83 f/s\n",
            "182750: done 183 games, mean reward -20.510, speed 0.00 f/s\n",
            "183200: done 184 games, mean reward -20.520, speed 739.37 f/s\n",
            "183250: done 185 games, mean reward -20.500, speed 714.60 f/s\n",
            "183850: done 186 games, mean reward -20.500, speed 760.07 f/s\n",
            "184700: done 187 games, mean reward -20.510, speed 780.32 f/s\n",
            "185100: done 188 games, mean reward -20.500, speed 735.09 f/s\n",
            "186250: done 189 games, mean reward -20.500, speed 762.15 f/s\n",
            "187650: done 190 games, mean reward -20.490, speed 760.96 f/s\n",
            "187650: done 191 games, mean reward -20.490, speed 0.00 f/s\n",
            "189950: done 192 games, mean reward -20.470, speed 771.87 f/s\n",
            "190950: done 193 games, mean reward -20.450, speed 761.93 f/s\n",
            "191400: done 194 games, mean reward -20.450, speed 751.22 f/s\n",
            "192150: done 195 games, mean reward -20.450, speed 766.23 f/s\n",
            "192300: done 196 games, mean reward -20.450, speed 740.81 f/s\n",
            "200550: done 197 games, mean reward -20.440, speed 772.98 f/s\n",
            "201150: done 198 games, mean reward -20.460, speed 758.78 f/s\n",
            "203800: done 199 games, mean reward -20.470, speed 772.60 f/s\n",
            "204100: done 200 games, mean reward -20.470, speed 763.79 f/s\n",
            "207250: done 201 games, mean reward -20.460, speed 772.38 f/s\n",
            "212200: done 202 games, mean reward -20.460, speed 773.82 f/s\n",
            "212700: done 203 games, mean reward -20.450, speed 747.68 f/s\n",
            "212700: done 204 games, mean reward -20.450, speed 0.00 f/s\n",
            "213050: done 205 games, mean reward -20.450, speed 752.08 f/s\n",
            "214250: done 206 games, mean reward -20.440, speed 769.58 f/s\n",
            "214450: done 207 games, mean reward -20.440, speed 712.09 f/s\n",
            "214550: done 208 games, mean reward -20.450, speed 683.20 f/s\n",
            "214600: done 209 games, mean reward -20.430, speed 692.15 f/s\n",
            "214650: done 210 games, mean reward -20.430, speed 701.40 f/s\n",
            "215400: done 211 games, mean reward -20.420, speed 760.79 f/s\n",
            "215850: done 212 games, mean reward -20.420, speed 744.41 f/s\n",
            "216050: done 213 games, mean reward -20.420, speed 730.44 f/s\n",
            "216050: done 214 games, mean reward -20.420, speed 0.00 f/s\n",
            "218500: done 215 games, mean reward -20.420, speed 765.78 f/s\n",
            "218500: done 216 games, mean reward -20.420, speed 0.00 f/s\n",
            "219700: done 217 games, mean reward -20.400, speed 774.29 f/s\n",
            "220550: done 218 games, mean reward -20.410, speed 749.63 f/s\n",
            "220550: done 219 games, mean reward -20.400, speed 0.00 f/s\n",
            "220750: done 220 games, mean reward -20.410, speed 754.79 f/s\n",
            "221950: done 221 games, mean reward -20.410, speed 772.16 f/s\n",
            "222350: done 222 games, mean reward -20.400, speed 737.94 f/s\n",
            "223500: done 223 games, mean reward -20.390, speed 762.68 f/s\n",
            "223850: done 224 games, mean reward -20.390, speed 769.14 f/s\n",
            "224050: done 225 games, mean reward -20.390, speed 721.04 f/s\n",
            "224300: done 226 games, mean reward -20.390, speed 744.64 f/s\n",
            "225350: done 227 games, mean reward -20.370, speed 765.60 f/s\n",
            "225800: done 228 games, mean reward -20.360, speed 743.08 f/s\n",
            "225800: done 229 games, mean reward -20.370, speed 0.00 f/s\n",
            "226400: done 230 games, mean reward -20.350, speed 774.94 f/s\n",
            "226600: done 231 games, mean reward -20.350, speed 729.69 f/s\n",
            "227650: done 232 games, mean reward -20.350, speed 772.95 f/s\n",
            "227700: done 233 games, mean reward -20.350, speed 714.17 f/s\n",
            "227750: done 234 games, mean reward -20.370, speed 528.32 f/s\n",
            "227750: done 235 games, mean reward -20.370, speed 0.00 f/s\n",
            "228500: done 236 games, mean reward -20.370, speed 763.89 f/s\n",
            "229250: done 237 games, mean reward -20.360, speed 765.03 f/s\n",
            "229600: done 238 games, mean reward -20.350, speed 767.15 f/s\n",
            "234650: done 239 games, mean reward -20.360, speed 771.88 f/s\n",
            "236550: done 240 games, mean reward -20.360, speed 774.70 f/s\n",
            "237050: done 241 games, mean reward -20.390, speed 778.29 f/s\n",
            "237200: done 242 games, mean reward -20.380, speed 685.64 f/s\n",
            "237400: done 243 games, mean reward -20.380, speed 768.76 f/s\n",
            "241500: done 244 games, mean reward -20.370, speed 766.68 f/s\n",
            "241900: done 245 games, mean reward -20.370, speed 759.76 f/s\n",
            "246300: done 246 games, mean reward -20.360, speed 768.16 f/s\n",
            "247500: done 247 games, mean reward -20.350, speed 775.12 f/s\n",
            "248200: done 248 games, mean reward -20.370, speed 759.67 f/s\n",
            "248600: done 249 games, mean reward -20.370, speed 742.82 f/s\n",
            "253450: done 250 games, mean reward -20.370, speed 771.22 f/s\n",
            "253700: done 251 games, mean reward -20.370, speed 748.89 f/s\n",
            "253800: done 252 games, mean reward -20.350, speed 723.76 f/s\n",
            "253800: done 253 games, mean reward -20.350, speed 0.00 f/s\n",
            "254400: done 254 games, mean reward -20.360, speed 761.75 f/s\n",
            "255050: done 255 games, mean reward -20.350, speed 760.91 f/s\n",
            "255100: done 256 games, mean reward -20.350, speed 714.28 f/s\n",
            "256600: done 257 games, mean reward -20.350, speed 770.16 f/s\n",
            "257550: done 258 games, mean reward -20.350, speed 759.34 f/s\n",
            "258150: done 259 games, mean reward -20.350, speed 768.78 f/s\n",
            "260450: done 260 games, mean reward -20.330, speed 767.84 f/s\n",
            "260950: done 261 games, mean reward -20.320, speed 761.34 f/s\n",
            "261050: done 262 games, mean reward -20.320, speed 701.11 f/s\n",
            "261750: done 263 games, mean reward -20.300, speed 772.93 f/s\n",
            "262250: done 264 games, mean reward -20.300, speed 761.63 f/s\n",
            "263050: done 265 games, mean reward -20.300, speed 758.07 f/s\n",
            "263250: done 266 games, mean reward -20.300, speed 763.35 f/s\n",
            "265150: done 267 games, mean reward -20.310, speed 772.14 f/s\n",
            "266150: done 268 games, mean reward -20.290, speed 762.85 f/s\n",
            "266600: done 269 games, mean reward -20.280, speed 760.98 f/s\n",
            "266900: done 270 games, mean reward -20.280, speed 729.10 f/s\n",
            "267000: done 271 games, mean reward -20.270, speed 764.88 f/s\n",
            "267100: done 272 games, mean reward -20.270, speed 691.30 f/s\n",
            "267850: done 273 games, mean reward -20.270, speed 764.98 f/s\n",
            "268850: done 274 games, mean reward -20.270, speed 768.79 f/s\n",
            "268900: done 275 games, mean reward -20.280, speed 712.23 f/s\n",
            "269700: done 276 games, mean reward -20.290, speed 761.04 f/s\n",
            "269750: done 277 games, mean reward -20.290, speed 716.49 f/s\n",
            "270350: done 278 games, mean reward -20.280, speed 766.28 f/s\n",
            "271550: done 279 games, mean reward -20.280, speed 775.49 f/s\n",
            "272000: done 280 games, mean reward -20.290, speed 752.33 f/s\n",
            "272900: done 281 games, mean reward -20.300, speed 766.78 f/s\n",
            "274250: done 282 games, mean reward -20.310, speed 777.10 f/s\n",
            "275200: done 283 games, mean reward -20.310, speed 759.52 f/s\n",
            "276350: done 284 games, mean reward -20.300, speed 773.89 f/s\n",
            "276500: done 285 games, mean reward -20.320, speed 675.61 f/s\n",
            "278300: done 286 games, mean reward -20.330, speed 767.13 f/s\n",
            "279150: done 287 games, mean reward -20.300, speed 770.55 f/s\n",
            "279200: done 288 games, mean reward -20.290, speed 587.26 f/s\n",
            "279300: done 289 games, mean reward -20.300, speed 696.75 f/s\n",
            "280200: done 290 games, mean reward -20.320, speed 767.49 f/s\n",
            "283600: done 291 games, mean reward -20.300, speed 774.15 f/s\n",
            "283900: done 292 games, mean reward -20.310, speed 757.97 f/s\n",
            "287800: done 293 games, mean reward -20.320, speed 771.94 f/s\n",
            "290200: done 294 games, mean reward -20.310, speed 770.79 f/s\n",
            "293150: done 295 games, mean reward -20.310, speed 772.87 f/s\n",
            "294350: done 296 games, mean reward -20.310, speed 770.54 f/s\n",
            "294450: done 297 games, mean reward -20.320, speed 693.76 f/s\n",
            "295450: done 298 games, mean reward -20.300, speed 770.08 f/s\n",
            "297350: done 299 games, mean reward -20.300, speed 772.24 f/s\n",
            "297400: done 300 games, mean reward -20.290, speed 730.21 f/s\n",
            "297600: done 301 games, mean reward -20.290, speed 703.83 f/s\n",
            "297600: done 302 games, mean reward -20.290, speed 0.00 f/s\n",
            "297650: done 303 games, mean reward -20.300, speed 710.26 f/s\n",
            "298000: done 304 games, mean reward -20.300, speed 746.56 f/s\n",
            "298400: done 305 games, mean reward -20.290, speed 765.68 f/s\n",
            "300100: done 306 games, mean reward -20.300, speed 775.33 f/s\n",
            "300700: done 307 games, mean reward -20.300, speed 759.80 f/s\n",
            "301250: done 308 games, mean reward -20.300, speed 746.87 f/s\n",
            "301950: done 309 games, mean reward -20.320, speed 756.53 f/s\n",
            "302000: done 310 games, mean reward -20.300, speed 574.55 f/s\n",
            "303550: done 311 games, mean reward -20.280, speed 771.01 f/s\n",
            "304450: done 312 games, mean reward -20.290, speed 763.03 f/s\n",
            "307850: done 313 games, mean reward -20.290, speed 773.80 f/s\n",
            "308200: done 314 games, mean reward -20.280, speed 774.86 f/s\n",
            "308850: done 315 games, mean reward -20.280, speed 769.39 f/s\n",
            "309000: done 316 games, mean reward -20.280, speed 690.25 f/s\n",
            "309250: done 317 games, mean reward -20.300, speed 748.10 f/s\n",
            "310350: done 318 games, mean reward -20.300, speed 767.82 f/s\n",
            "310950: done 319 games, mean reward -20.300, speed 740.21 f/s\n",
            "311050: done 320 games, mean reward -20.310, speed 712.95 f/s\n",
            "311450: done 321 games, mean reward -20.310, speed 764.53 f/s\n",
            "311800: done 322 games, mean reward -20.310, speed 786.03 f/s\n",
            "315400: done 323 games, mean reward -20.310, speed 770.39 f/s\n",
            "315700: done 324 games, mean reward -20.290, speed 768.31 f/s\n",
            "316650: done 325 games, mean reward -20.290, speed 775.62 f/s\n",
            "316750: done 326 games, mean reward -20.290, speed 699.86 f/s\n",
            "318150: done 327 games, mean reward -20.310, speed 775.23 f/s\n",
            "319000: done 328 games, mean reward -20.310, speed 738.61 f/s\n",
            "319500: done 329 games, mean reward -20.320, speed 729.87 f/s\n",
            "319700: done 330 games, mean reward -20.340, speed 762.69 f/s\n",
            "320200: done 331 games, mean reward -20.330, speed 757.09 f/s\n",
            "321650: done 332 games, mean reward -20.320, speed 771.03 f/s\n",
            "321950: done 333 games, mean reward -20.300, speed 736.04 f/s\n",
            "322200: done 334 games, mean reward -20.300, speed 750.91 f/s\n",
            "322300: done 335 games, mean reward -20.310, speed 785.67 f/s\n",
            "322650: done 336 games, mean reward -20.320, speed 749.51 f/s\n",
            "323200: done 337 games, mean reward -20.330, speed 737.28 f/s\n",
            "323200: done 338 games, mean reward -20.330, speed 0.00 f/s\n",
            "325600: done 339 games, mean reward -20.310, speed 773.10 f/s\n",
            "325650: done 340 games, mean reward -20.300, speed 592.79 f/s\n",
            "334250: done 341 games, mean reward -20.290, speed 772.38 f/s\n",
            "335200: done 342 games, mean reward -20.290, speed 759.14 f/s\n",
            "335200: done 343 games, mean reward -20.290, speed 0.00 f/s\n",
            "336650: done 344 games, mean reward -20.300, speed 748.85 f/s\n",
            "337550: done 345 games, mean reward -20.280, speed 760.70 f/s\n",
            "338700: done 346 games, mean reward -20.290, speed 776.83 f/s\n",
            "339700: done 347 games, mean reward -20.300, speed 784.80 f/s\n",
            "342350: done 348 games, mean reward -20.300, speed 775.79 f/s\n",
            "343050: done 349 games, mean reward -20.300, speed 760.77 f/s\n",
            "344450: done 350 games, mean reward -20.290, speed 772.49 f/s\n",
            "345550: done 351 games, mean reward -20.290, speed 748.85 f/s\n",
            "345750: done 352 games, mean reward -20.300, speed 704.59 f/s\n",
            "345800: done 353 games, mean reward -20.290, speed 703.73 f/s\n",
            "346300: done 354 games, mean reward -20.280, speed 755.22 f/s\n",
            "346350: done 355 games, mean reward -20.280, speed 713.12 f/s\n",
            "346650: done 356 games, mean reward -20.270, speed 722.78 f/s\n",
            "348050: done 357 games, mean reward -20.250, speed 765.90 f/s\n",
            "349050: done 358 games, mean reward -20.260, speed 780.85 f/s\n",
            "349400: done 359 games, mean reward -20.260, speed 754.93 f/s\n",
            "349900: done 360 games, mean reward -20.270, speed 756.28 f/s\n",
            "350750: done 361 games, mean reward -20.280, speed 766.78 f/s\n",
            "351400: done 362 games, mean reward -20.270, speed 767.97 f/s\n",
            "352200: done 363 games, mean reward -20.290, speed 770.36 f/s\n",
            "353150: done 364 games, mean reward -20.290, speed 777.21 f/s\n",
            "354650: done 365 games, mean reward -20.250, speed 755.48 f/s\n",
            "355650: done 366 games, mean reward -20.240, speed 763.76 f/s\n",
            "356550: done 367 games, mean reward -20.240, speed 770.19 f/s\n",
            "358600: done 368 games, mean reward -20.240, speed 769.73 f/s\n",
            "358750: done 369 games, mean reward -20.240, speed 729.13 f/s\n",
            "358850: done 370 games, mean reward -20.230, speed 695.51 f/s\n",
            "360900: done 371 games, mean reward -20.240, speed 772.27 f/s\n",
            "361300: done 372 games, mean reward -20.240, speed 759.21 f/s\n",
            "361650: done 373 games, mean reward -20.240, speed 751.74 f/s\n",
            "361900: done 374 games, mean reward -20.240, speed 749.55 f/s\n",
            "363500: done 375 games, mean reward -20.210, speed 762.11 f/s\n",
            "364150: done 376 games, mean reward -20.210, speed 770.18 f/s\n",
            "364250: done 377 games, mean reward -20.220, speed 696.97 f/s\n",
            "364450: done 378 games, mean reward -20.230, speed 720.73 f/s\n",
            "364700: done 379 games, mean reward -20.230, speed 752.85 f/s\n",
            "364950: done 380 games, mean reward -20.220, speed 751.63 f/s\n",
            "365150: done 381 games, mean reward -20.220, speed 761.48 f/s\n",
            "365200: done 382 games, mean reward -20.220, speed 590.78 f/s\n",
            "365800: done 383 games, mean reward -20.220, speed 776.49 f/s\n",
            "365900: done 384 games, mean reward -20.210, speed 701.03 f/s\n",
            "366750: done 385 games, mean reward -20.200, speed 762.75 f/s\n",
            "369100: done 386 games, mean reward -20.170, speed 776.27 f/s\n",
            "372700: done 387 games, mean reward -20.200, speed 768.00 f/s\n",
            "375800: done 388 games, mean reward -20.220, speed 776.91 f/s\n",
            "378350: done 389 games, mean reward -20.220, speed 774.80 f/s\n",
            "378650: done 390 games, mean reward -20.220, speed 742.17 f/s\n",
            "379100: done 391 games, mean reward -20.240, speed 777.19 f/s\n",
            "381900: done 392 games, mean reward -20.240, speed 768.10 f/s\n",
            "382800: done 393 games, mean reward -20.250, speed 771.35 f/s\n",
            "383300: done 394 games, mean reward -20.260, speed 766.30 f/s\n",
            "384000: done 395 games, mean reward -20.240, speed 764.13 f/s\n",
            "385200: done 396 games, mean reward -20.210, speed 776.08 f/s\n",
            "388550: done 397 games, mean reward -20.220, speed 777.98 f/s\n",
            "390250: done 398 games, mean reward -20.240, speed 764.18 f/s\n",
            "390600: done 399 games, mean reward -20.250, speed 754.91 f/s\n",
            "392400: done 400 games, mean reward -20.270, speed 776.28 f/s\n",
            "392400: done 401 games, mean reward -20.270, speed 0.00 f/s\n",
            "392800: done 402 games, mean reward -20.270, speed 761.03 f/s\n",
            "394200: done 403 games, mean reward -20.260, speed 770.62 f/s\n",
            "394250: done 404 games, mean reward -20.240, speed 587.24 f/s\n",
            "395500: done 405 games, mean reward -20.240, speed 779.69 f/s\n",
            "395750: done 406 games, mean reward -20.240, speed 752.63 f/s\n",
            "396050: done 407 games, mean reward -20.230, speed 735.24 f/s\n",
            "397150: done 408 games, mean reward -20.230, speed 780.40 f/s\n",
            "398200: done 409 games, mean reward -20.220, speed 767.74 f/s\n",
            "398400: done 410 games, mean reward -20.240, speed 717.90 f/s\n",
            "399800: done 411 games, mean reward -20.270, speed 779.88 f/s\n",
            "400000: done 412 games, mean reward -20.270, speed 730.89 f/s\n",
            "400500: done 413 games, mean reward -20.250, speed 786.29 f/s\n",
            "400800: done 414 games, mean reward -20.250, speed 739.43 f/s\n",
            "401600: done 415 games, mean reward -20.240, speed 774.11 f/s\n",
            "402000: done 416 games, mean reward -20.240, speed 767.84 f/s\n",
            "402200: done 417 games, mean reward -20.230, speed 730.54 f/s\n",
            "402750: done 418 games, mean reward -20.230, speed 777.33 f/s\n",
            "405800: done 419 games, mean reward -20.240, speed 775.91 f/s\n",
            "405850: done 420 games, mean reward -20.210, speed 720.84 f/s\n",
            "406200: done 421 games, mean reward -20.210, speed 740.28 f/s\n",
            "406300: done 422 games, mean reward -20.210, speed 699.15 f/s\n",
            "406700: done 423 games, mean reward -20.210, speed 767.36 f/s\n",
            "408050: done 424 games, mean reward -20.220, speed 766.87 f/s\n",
            "408550: done 425 games, mean reward -20.220, speed 768.34 f/s\n",
            "408750: done 426 games, mean reward -20.210, speed 730.94 f/s\n",
            "409100: done 427 games, mean reward -20.210, speed 752.48 f/s\n",
            "410000: done 428 games, mean reward -20.210, speed 778.25 f/s\n",
            "410050: done 429 games, mean reward -20.210, speed 735.11 f/s\n",
            "410500: done 430 games, mean reward -20.210, speed 757.19 f/s\n",
            "410750: done 431 games, mean reward -20.220, speed 790.79 f/s\n",
            "410800: done 432 games, mean reward -20.230, speed 591.25 f/s\n",
            "415250: done 433 games, mean reward -20.240, speed 778.85 f/s\n",
            "415550: done 434 games, mean reward -20.230, speed 758.90 f/s\n",
            "417950: done 435 games, mean reward -20.230, speed 769.95 f/s\n",
            "420000: done 436 games, mean reward -20.230, speed 780.11 f/s\n",
            "421250: done 437 games, mean reward -20.230, speed 772.85 f/s\n",
            "421600: done 438 games, mean reward -20.220, speed 782.09 f/s\n",
            "424800: done 439 games, mean reward -20.230, speed 778.02 f/s\n",
            "426900: done 440 games, mean reward -20.210, speed 778.21 f/s\n",
            "429150: done 441 games, mean reward -20.200, speed 774.27 f/s\n",
            "429900: done 442 games, mean reward -20.180, speed 771.05 f/s\n",
            "430450: done 443 games, mean reward -20.180, speed 775.96 f/s\n",
            "430500: done 444 games, mean reward -20.180, speed 592.64 f/s\n",
            "431200: done 445 games, mean reward -20.200, speed 776.42 f/s\n",
            "432400: done 446 games, mean reward -20.190, speed 770.87 f/s\n",
            "433250: done 447 games, mean reward -20.170, speed 753.46 f/s\n",
            "434450: done 448 games, mean reward -20.170, speed 767.49 f/s\n",
            "435450: done 449 games, mean reward -20.170, speed 782.90 f/s\n",
            "435550: done 450 games, mean reward -20.210, speed 698.20 f/s\n",
            "436400: done 451 games, mean reward -20.200, speed 765.63 f/s\n",
            "437200: done 452 games, mean reward -20.200, speed 772.64 f/s\n",
            "437400: done 453 games, mean reward -20.210, speed 732.53 f/s\n",
            "437800: done 454 games, mean reward -20.220, speed 768.87 f/s\n",
            "440750: done 455 games, mean reward -20.220, speed 772.12 f/s\n",
            "440900: done 456 games, mean reward -20.230, speed 712.11 f/s\n",
            "440900: done 457 games, mean reward -20.250, speed 0.00 f/s\n",
            "441050: done 458 games, mean reward -20.250, speed 756.35 f/s\n",
            "441350: done 459 games, mean reward -20.250, speed 729.71 f/s\n",
            "442250: done 460 games, mean reward -20.260, speed 767.37 f/s\n",
            "443000: done 461 games, mean reward -20.260, speed 780.58 f/s\n",
            "445300: done 462 games, mean reward -20.260, speed 778.95 f/s\n",
            "446200: done 463 games, mean reward -20.260, speed 773.38 f/s\n",
            "447250: done 464 games, mean reward -20.260, speed 763.65 f/s\n",
            "447550: done 465 games, mean reward -20.300, speed 764.40 f/s\n",
            "448100: done 466 games, mean reward -20.310, speed 773.51 f/s\n",
            "449050: done 467 games, mean reward -20.300, speed 769.20 f/s\n",
            "449750: done 468 games, mean reward -20.310, speed 780.95 f/s\n",
            "449900: done 469 games, mean reward -20.320, speed 744.09 f/s\n",
            "450100: done 470 games, mean reward -20.330, speed 717.50 f/s\n",
            "450850: done 471 games, mean reward -20.320, speed 756.39 f/s\n",
            "451250: done 472 games, mean reward -20.320, speed 751.59 f/s\n",
            "452050: done 473 games, mean reward -20.330, speed 770.71 f/s\n",
            "452150: done 474 games, mean reward -20.330, speed 701.98 f/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "test_env = gym.make(\"PongNoFrameskip-v4\", render_mode=\"rgb_array\")\n",
        "test_env = ptan.common.wrappers.wrap_dqn(test_env)\n",
        "test_env = RecordVideo(test_env, video_folder=\"./videos\", episode_trigger=lambda ep: True)\n",
        "net.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "\n",
        "state = test_env.reset()[0]\n",
        "total_reward = 0.0\n",
        "frames = []\n",
        "\n",
        "while True:\n",
        "    state_v = torch.tensor(np.array([state]), device=device)\n",
        "    logits, _ = net(state_v)\n",
        "    action = torch.argmax(logits, dim=1).item()\n",
        "    next_state, reward, terminated, truncated, _ = test_env.step(action)\n",
        "    frames.append(test_env.render())\n",
        "    total_reward += reward\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "    state = next_state\n",
        "\n",
        "test_env.close()\n",
        "print(f\"Total reward during test: {total_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DSm0Pc1xq6fe",
        "outputId": "b78fed46-ac43-4bcc-a05f-2d44e9fa6e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'make_env' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6cc170fc3986>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordVideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ALE/Pong-v5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecordVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./videos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_trigger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import os\n",
        "\n",
        "event_path = [os.path.join(\"runs\", d) for d in os.listdir(\"runs\") if os.path.isdir(os.path.join(\"runs\", d))][0]\n",
        "event_acc = EventAccumulator(event_path)\n",
        "event_acc.Reload()\n",
        "\n",
        "rewards = event_acc.Scalars(\"reward_100\")\n",
        "steps = [s.step for s in rewards]\n",
        "values = [s.value for s in rewards]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(steps, values)\n",
        "plt.title(\"Średnia nagroda (ostatnie 100 gier)\")\n",
        "plt.xlabel(\"Krok treningowy\")\n",
        "plt.ylabel(\"Średnia nagroda\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R8ysbDCgq9k4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}