{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Helena26-ai/Rainforcement_project/blob/Helena/Noisy_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqlkUdnaIxDr",
        "outputId": "ad3d42b8-3765-49a0-a2af-e67965618ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Zainstaluj PyTorch z obsługą CUDA 12.4\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xybP1dEDHQl",
        "outputId": "24eefaba-19f3-4409-dc4f-076fd51f3dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium==0.29.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]==0.29.1) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->gymnasium[accept-rom-license,atari]==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: autorom~=0.4.2 in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (0.4.2)\n",
            "Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (4.67.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (0.6.1)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.11/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]==0.29.1) (6.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]==0.29.1) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]==0.29.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n13ddpDWDPaw",
        "outputId": "55c626a7-7e43-4b4d-f6c5-14745867b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Requirement already satisfied: tensordict<0.9.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from torchrl) (0.8.2)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.1->torchrl) (8.7.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.1->torchrl) (3.10.18)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict<0.9.0,>=0.8.1->torchrl) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->torchrl) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Zainstaluj biblioteki RL i narzędzia\n",
        "!pip install torchrl\n",
        "!pip install stable-baselines3 tensorboard matplotlib -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JF88_n-vDTJn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import collections\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from torchrl.modules import NoisyLinear\n",
        "from dataclasses import dataclass\n",
        "import imageio.v2 as imageio\n",
        "from stable_baselines3.common.atari_wrappers import AtariWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c4w4YRSEH4ST"
      },
      "outputs": [],
      "source": [
        "# === Wrappery ===\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs = self.observation_space\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(),\n",
        "            shape=(obs.shape[2], obs.shape[0], obs.shape[1]), dtype=obs.dtype)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps):\n",
        "        super().__init__(env)\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "        obs = env.observation_space\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.repeat(obs.low, n_steps, axis=0),\n",
        "            high=np.repeat(obs.high, n_steps, axis=0),\n",
        "            dtype=obs.dtype)\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        for _ in range(self.buffer.maxlen - 1):\n",
        "            self.buffer.append(self.env.observation_space.low)\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        return self.observation(obs), info\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer)\n",
        "\n",
        "def make_env(env_name: str, **kwargs):\n",
        "    env = gym.make(env_name, **kwargs)\n",
        "    env = AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=4)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UdiGvib1H7Fv"
      },
      "outputs": [],
      "source": [
        "# === Parametry ===\n",
        "ENV_NAME = \"PongNoFrameskip-v4\"\n",
        "MEAN_REWARD_BOUND = 19\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 100000\n",
        "LEARNING_RATE = 1e-4 #7.14e-5\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "REPLAY_START_SIZE = 10000\n",
        "TEST_VIDEO_PATH = \"noisy_dqn_test_run.mp4\"\n",
        "MODEL_SAVE_PATH = \"noisy_dqn_best_model.dat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "six82NzeIBdr"
      },
      "outputs": [],
      "source": [
        "# === Sieć Noisy DQN ===\n",
        "class NoisyDQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        conv_out_size = self.conv(torch.zeros(1, *input_shape)).shape[1]\n",
        "        self.fc1 = NoisyLinear(conv_out_size, 512)\n",
        "        self.fc2 = NoisyLinear(512, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255.0\n",
        "        x = self.conv(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "    def reset_noise(self):\n",
        "        self.fc1.reset_noise()\n",
        "        self.fc2.reset_noise()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iBX3hxw6IHe0"
      },
      "outputs": [],
      "source": [
        "# === Bufor doświadczeń ===\n",
        "@dataclass\n",
        "class Experience:\n",
        "    state: np.ndarray\n",
        "    action: int\n",
        "    reward: float\n",
        "    done: bool\n",
        "    new_state: np.ndarray\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, exp):\n",
        "        self.buffer.append(exp)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "        batch = [self.buffer[idx] for idx in indices]\n",
        "        return batch\n",
        "\n",
        "# === Agent ===\n",
        "class Agent:\n",
        "    def __init__(self, env, buffer):\n",
        "        self.env = env\n",
        "        self.buffer = buffer\n",
        "        self.state, _ = env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def play_step(self, net, device):\n",
        "        state_v = torch.tensor(np.array([self.state]), device=device)\n",
        "        q_vals = net(state_v)\n",
        "        action = torch.argmax(q_vals).item()\n",
        "\n",
        "        new_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "        done = terminated or truncated\n",
        "        exp = Experience(self.state, action, reward, done, new_state)\n",
        "        self.buffer.append(exp)\n",
        "        self.total_reward += reward\n",
        "        self.state = new_state\n",
        "\n",
        "        if done:\n",
        "            r = self.total_reward\n",
        "            self.state, _ = self.env.reset()\n",
        "            self.total_reward = 0.0\n",
        "            return r\n",
        "        return None\n",
        "\n",
        "# === Przetwarzanie batcha ===\n",
        "def batch_to_tensors(batch, device):\n",
        "    states = torch.tensor(np.array([e.state for e in batch]), device=device)\n",
        "    actions = torch.tensor([e.action for e in batch], dtype=torch.long, device=device)\n",
        "    rewards = torch.tensor([e.reward for e in batch], dtype=torch.float32, device=device)\n",
        "    dones = torch.tensor([e.done for e in batch], dtype=torch.bool, device=device)\n",
        "    next_states = torch.tensor(np.array([e.new_state for e in batch]), device=device)\n",
        "    return states, actions, rewards, dones, next_states\n",
        "\n",
        "def calc_loss(batch, net, tgt_net, device):\n",
        "    states, actions, rewards, dones, next_states = batch_to_tensors(batch, device)\n",
        "    state_action_values = net(states).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "        next_state_values = tgt_net(next_states).max(1)[0]\n",
        "        next_state_values[dones] = 0.0\n",
        "    expected_values = rewards + GAMMA * next_state_values\n",
        "    return nn.MSELoss()(state_action_values, expected_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWnoy0LtIXJO",
        "outputId": "8f4f1dd4-a8a0-498b-8ddb-9a8b6fd81526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "762: games 1, reward -21.000, speed 411.41 f/s\n",
            "1524: games 2, reward -21.000, speed 417.69 f/s\n",
            "2364: games 3, reward -20.667, speed 441.49 f/s\n",
            "3246: games 4, reward -20.750, speed 439.78 f/s\n",
            "4008: games 5, reward -20.800, speed 442.72 f/s\n",
            "4830: games 6, reward -20.833, speed 429.59 f/s\n",
            "5592: games 7, reward -20.857, speed 433.75 f/s\n",
            "6354: games 8, reward -20.875, speed 434.75 f/s\n",
            "7116: games 9, reward -20.889, speed 438.45 f/s\n",
            "7878: games 10, reward -20.900, speed 445.38 f/s\n",
            "8718: games 11, reward -20.818, speed 440.12 f/s\n",
            "9480: games 12, reward -20.833, speed 443.70 f/s\n",
            "10242: games 13, reward -20.846, speed 230.51 f/s\n",
            "11306: games 14, reward -20.857, speed 119.31 f/s\n",
            "12202: games 15, reward -20.800, speed 118.74 f/s\n",
            "13114: games 16, reward -20.812, speed 118.97 f/s\n",
            "14250: games 17, reward -20.765, speed 118.40 f/s\n",
            "15109: games 18, reward -20.722, speed 117.77 f/s\n",
            "15950: games 19, reward -20.684, speed 117.91 f/s\n",
            "16786: games 20, reward -20.650, speed 118.80 f/s\n",
            "17835: games 21, reward -20.619, speed 118.52 f/s\n",
            "18658: games 22, reward -20.636, speed 116.70 f/s\n",
            "19694: games 23, reward -20.565, speed 115.89 f/s\n",
            "20475: games 24, reward -20.583, speed 113.86 f/s\n",
            "21311: games 25, reward -20.560, speed 117.23 f/s\n",
            "22134: games 26, reward -20.577, speed 111.45 f/s\n",
            "23035: games 27, reward -20.593, speed 115.78 f/s\n",
            "24164: games 28, reward -20.571, speed 114.76 f/s\n",
            "25014: games 29, reward -20.586, speed 114.56 f/s\n",
            "25871: games 30, reward -20.567, speed 114.96 f/s\n",
            "26633: games 31, reward -20.581, speed 115.26 f/s\n",
            "27621: games 32, reward -20.594, speed 114.60 f/s\n",
            "28842: games 33, reward -20.515, speed 114.41 f/s\n",
            "30044: games 34, reward -20.500, speed 112.30 f/s\n",
            "30991: games 35, reward -20.457, speed 112.87 f/s\n",
            "32258: games 36, reward -20.389, speed 111.81 f/s\n",
            "33551: games 37, reward -20.351, speed 110.49 f/s\n",
            "35111: games 38, reward -20.184, speed 112.22 f/s\n",
            "36380: games 39, reward -20.179, speed 111.55 f/s\n",
            "37474: games 40, reward -20.200, speed 111.73 f/s\n",
            "38440: games 41, reward -20.220, speed 113.29 f/s\n",
            "39572: games 42, reward -20.190, speed 110.66 f/s\n",
            "41044: games 43, reward -20.093, speed 111.64 f/s\n",
            "42522: games 44, reward -20.045, speed 110.90 f/s\n",
            "43631: games 45, reward -20.022, speed 111.05 f/s\n",
            "45085: games 46, reward -20.022, speed 109.46 f/s\n",
            "46119: games 47, reward -20.021, speed 110.09 f/s\n",
            "47421: games 48, reward -20.021, speed 110.33 f/s\n",
            "49160: games 49, reward -19.939, speed 110.17 f/s\n",
            "50873: games 50, reward -19.920, speed 108.89 f/s\n",
            "52831: games 51, reward -19.765, speed 109.25 f/s\n",
            "55301: games 52, reward -19.692, speed 108.47 f/s\n",
            "57664: games 53, reward -19.547, speed 109.66 f/s\n",
            "60307: games 54, reward -19.444, speed 109.40 f/s\n",
            "62120: games 55, reward -19.382, speed 109.28 f/s\n",
            "64139: games 56, reward -19.375, speed 108.04 f/s\n",
            "65930: games 57, reward -19.351, speed 106.60 f/s\n",
            "68281: games 58, reward -19.310, speed 107.00 f/s\n",
            "70742: games 59, reward -19.237, speed 106.32 f/s\n",
            "72779: games 60, reward -19.183, speed 105.40 f/s\n",
            "74965: games 61, reward -19.115, speed 105.89 f/s\n",
            "77134: games 62, reward -19.048, speed 103.83 f/s\n",
            "79894: games 63, reward -18.937, speed 104.40 f/s\n",
            "82729: games 64, reward -18.812, speed 103.23 f/s\n",
            "85800: games 65, reward -18.738, speed 101.65 f/s\n",
            "88369: games 66, reward -18.667, speed 101.19 f/s\n",
            "91902: games 67, reward -18.582, speed 100.67 f/s\n",
            "95421: games 68, reward -18.426, speed 101.21 f/s\n",
            "98978: games 69, reward -18.333, speed 101.34 f/s\n",
            "102460: games 70, reward -18.257, speed 100.33 f/s\n",
            "105544: games 71, reward -18.239, speed 101.44 f/s\n",
            "109001: games 72, reward -18.208, speed 100.78 f/s\n",
            "113365: games 73, reward -18.096, speed 101.21 f/s\n",
            "117047: games 74, reward -18.027, speed 101.55 f/s\n",
            "121183: games 75, reward -17.920, speed 101.51 f/s\n",
            "124074: games 76, reward -17.895, speed 101.35 f/s\n",
            "127450: games 77, reward -17.818, speed 101.52 f/s\n",
            "129594: games 78, reward -17.821, speed 100.61 f/s\n",
            "133225: games 79, reward -17.747, speed 98.80 f/s\n",
            "136413: games 80, reward -17.712, speed 99.95 f/s\n",
            "139629: games 81, reward -17.605, speed 100.12 f/s\n",
            "142953: games 82, reward -17.561, speed 100.34 f/s\n",
            "147179: games 83, reward -17.458, speed 99.46 f/s\n",
            "150556: games 84, reward -17.405, speed 98.84 f/s\n",
            "153716: games 85, reward -17.353, speed 99.41 f/s\n",
            "156463: games 86, reward -17.349, speed 96.34 f/s\n",
            "160696: games 87, reward -17.276, speed 99.84 f/s\n",
            "164279: games 88, reward -17.170, speed 98.68 f/s\n",
            "169572: games 89, reward -17.045, speed 99.45 f/s\n",
            "173593: games 90, reward -16.978, speed 99.38 f/s\n",
            "178112: games 91, reward -16.857, speed 97.50 f/s\n",
            "181304: games 92, reward -16.826, speed 100.23 f/s\n",
            "185683: games 93, reward -16.753, speed 99.11 f/s\n",
            "190406: games 94, reward -16.628, speed 99.91 f/s\n",
            "194852: games 95, reward -16.484, speed 99.77 f/s\n",
            "200441: games 96, reward -16.333, speed 98.01 f/s\n",
            "205106: games 97, reward -16.268, speed 98.24 f/s\n",
            "210196: games 98, reward -16.061, speed 98.18 f/s\n",
            "214533: games 99, reward -15.828, speed 98.70 f/s\n",
            "219834: games 100, reward -15.690, speed 98.83 f/s\n",
            "225022: games 101, reward -15.460, speed 99.08 f/s\n",
            "229896: games 102, reward -15.230, speed 99.05 f/s\n",
            "234831: games 103, reward -15.000, speed 98.47 f/s\n",
            "239044: games 104, reward -14.830, speed 98.69 f/s\n",
            "243378: games 105, reward -14.660, speed 99.97 f/s\n",
            "247944: games 106, reward -14.370, speed 100.28 f/s\n",
            "253160: games 107, reward -14.090, speed 100.76 f/s\n",
            "257935: games 108, reward -13.870, speed 99.37 f/s\n",
            "263234: games 109, reward -13.690, speed 99.40 f/s\n",
            "266868: games 110, reward -13.410, speed 98.53 f/s\n",
            "270284: games 111, reward -13.160, speed 100.48 f/s\n",
            "274169: games 112, reward -13.030, speed 100.72 f/s\n",
            "278822: games 113, reward -12.830, speed 100.35 f/s\n",
            "284165: games 114, reward -12.610, speed 100.43 f/s\n",
            "288625: games 115, reward -12.370, speed 101.00 f/s\n",
            "293708: games 116, reward -12.180, speed 101.05 f/s\n",
            "297888: games 117, reward -11.940, speed 100.75 f/s\n",
            "301707: games 118, reward -11.770, speed 100.18 f/s\n",
            "305076: games 119, reward -11.500, speed 100.76 f/s\n",
            "309058: games 120, reward -11.240, speed 99.85 f/s\n",
            "313854: games 121, reward -11.000, speed 100.59 f/s\n",
            "318261: games 122, reward -10.780, speed 99.87 f/s\n",
            "322439: games 123, reward -10.560, speed 101.22 f/s\n",
            "326404: games 124, reward -10.310, speed 100.31 f/s\n",
            "330925: games 125, reward -10.090, speed 100.05 f/s\n",
            "334754: games 126, reward -9.820, speed 99.41 f/s\n",
            "338629: games 127, reward -9.540, speed 99.94 f/s\n",
            "342385: games 128, reward -9.250, speed 99.81 f/s\n",
            "346482: games 129, reward -9.010, speed 100.27 f/s\n",
            "350258: games 130, reward -8.750, speed 100.03 f/s\n",
            "353516: games 131, reward -8.450, speed 100.36 f/s\n",
            "357650: games 132, reward -8.220, speed 100.89 f/s\n",
            "360849: games 133, reward -7.940, speed 100.18 f/s\n",
            "364265: games 134, reward -7.680, speed 100.76 f/s\n",
            "368262: games 135, reward -7.480, speed 100.64 f/s\n",
            "371497: games 136, reward -7.210, speed 100.50 f/s\n",
            "375296: games 137, reward -6.930, speed 100.65 f/s\n",
            "378662: games 138, reward -6.740, speed 100.31 f/s\n",
            "382183: games 139, reward -6.500, speed 101.50 f/s\n",
            "385147: games 140, reward -6.190, speed 101.92 f/s\n",
            "388241: games 141, reward -5.890, speed 101.20 f/s\n",
            "392007: games 142, reward -5.640, speed 98.42 f/s\n",
            "395356: games 143, reward -5.390, speed 99.19 f/s\n",
            "398415: games 144, reward -5.100, speed 99.81 f/s\n",
            "401189: games 145, reward -4.800, speed 99.96 f/s\n",
            "403677: games 146, reward -4.470, speed 99.50 f/s\n",
            "406927: games 147, reward -4.190, speed 99.29 f/s\n",
            "410160: games 148, reward -3.900, speed 99.89 f/s\n",
            "413656: games 149, reward -3.660, speed 99.65 f/s\n",
            "417540: games 150, reward -3.410, speed 100.81 f/s\n",
            "421171: games 151, reward -3.200, speed 100.67 f/s\n",
            "424091: games 152, reward -2.930, speed 101.18 f/s\n",
            "426737: games 153, reward -2.660, speed 100.87 f/s\n",
            "429656: games 154, reward -2.420, speed 101.30 f/s\n",
            "432492: games 155, reward -2.130, speed 100.26 f/s\n",
            "435375: games 156, reward -1.800, speed 100.99 f/s\n",
            "439374: games 157, reward -1.550, speed 100.44 f/s\n",
            "442563: games 158, reward -1.280, speed 100.27 f/s\n",
            "445264: games 159, reward -1.000, speed 98.66 f/s\n",
            "448052: games 160, reward -0.710, speed 98.57 f/s\n",
            "450607: games 161, reward -0.420, speed 99.25 f/s\n",
            "453775: games 162, reward -0.170, speed 99.47 f/s\n",
            "456305: games 163, reward 0.100, speed 99.26 f/s\n",
            "458672: games 164, reward 0.360, speed 99.44 f/s\n",
            "461836: games 165, reward 0.630, speed 100.24 f/s\n",
            "464957: games 166, reward 0.890, speed 100.49 f/s\n",
            "467314: games 167, reward 1.190, speed 100.13 f/s\n",
            "469852: games 168, reward 1.410, speed 100.85 f/s\n",
            "472456: games 169, reward 1.690, speed 101.88 f/s\n",
            "474825: games 170, reward 1.960, speed 100.95 f/s\n",
            "477549: games 171, reward 2.250, speed 101.80 f/s\n",
            "480507: games 172, reward 2.560, speed 102.27 f/s\n",
            "482748: games 173, reward 2.840, speed 101.01 f/s\n",
            "485425: games 174, reward 3.090, speed 100.90 f/s\n",
            "488081: games 175, reward 3.340, speed 100.37 f/s\n",
            "490467: games 176, reward 3.670, speed 101.24 f/s\n",
            "492957: games 177, reward 3.920, speed 100.87 f/s\n",
            "495568: games 178, reward 4.250, speed 101.06 f/s\n",
            "497944: games 179, reward 4.530, speed 101.53 f/s\n",
            "500152: games 180, reward 4.840, speed 101.24 f/s\n",
            "502397: games 181, reward 5.110, speed 100.58 f/s\n",
            "504792: games 182, reward 5.390, speed 100.25 f/s\n",
            "507115: games 183, reward 5.650, speed 101.76 f/s\n",
            "509241: games 184, reward 5.970, speed 102.25 f/s\n",
            "511426: games 185, reward 6.250, speed 101.59 f/s\n",
            "513962: games 186, reward 6.590, speed 101.90 f/s\n",
            "516159: games 187, reward 6.870, speed 100.71 f/s\n",
            "518449: games 188, reward 7.130, speed 100.65 f/s\n",
            "520543: games 189, reward 7.370, speed 97.23 f/s\n",
            "522330: games 190, reward 7.680, speed 98.90 f/s\n",
            "524246: games 191, reward 7.940, speed 101.35 f/s\n",
            "526144: games 192, reward 8.270, speed 100.93 f/s\n",
            "528102: games 193, reward 8.560, speed 101.20 f/s\n",
            "530054: games 194, reward 8.810, speed 101.04 f/s\n",
            "532215: games 195, reward 9.010, speed 100.41 f/s\n",
            "534104: games 196, reward 9.210, speed 101.36 f/s\n",
            "536212: games 197, reward 9.490, speed 99.89 f/s\n",
            "538196: games 198, reward 9.640, speed 101.43 f/s\n",
            "539974: games 199, reward 9.770, speed 100.74 f/s\n",
            "541950: games 200, reward 9.990, speed 101.04 f/s\n",
            "543897: games 201, reward 10.150, speed 100.19 f/s\n",
            "545832: games 202, reward 10.330, speed 99.61 f/s\n",
            "547549: games 203, reward 10.500, speed 98.76 f/s\n",
            "549616: games 204, reward 10.740, speed 100.71 f/s\n",
            "551346: games 205, reward 10.980, speed 101.89 f/s\n",
            "553125: games 206, reward 11.100, speed 100.71 f/s\n",
            "554896: games 207, reward 11.230, speed 98.91 f/s\n",
            "556766: games 208, reward 11.420, speed 97.56 f/s\n",
            "558432: games 209, reward 11.650, speed 100.37 f/s\n",
            "560397: games 210, reward 11.790, speed 99.34 f/s\n",
            "562434: games 211, reward 11.930, speed 100.76 f/s\n",
            "564413: games 212, reward 12.190, speed 100.51 f/s\n",
            "566542: games 213, reward 12.400, speed 100.80 f/s\n",
            "568380: games 214, reward 12.590, speed 100.68 f/s\n",
            "570368: games 215, reward 12.750, speed 101.88 f/s\n",
            "572095: games 216, reward 12.970, speed 100.52 f/s\n",
            "573747: games 217, reward 13.140, speed 100.32 f/s\n",
            "575681: games 218, reward 13.370, speed 99.84 f/s\n",
            "577428: games 219, reward 13.500, speed 100.57 f/s\n",
            "579183: games 220, reward 13.640, speed 100.87 f/s\n",
            "580933: games 221, reward 13.800, speed 99.88 f/s\n",
            "582739: games 222, reward 13.980, speed 100.68 f/s\n",
            "584467: games 223, reward 14.150, speed 101.71 f/s\n",
            "586293: games 224, reward 14.300, speed 101.18 f/s\n",
            "588027: games 225, reward 14.480, speed 102.96 f/s\n",
            "589911: games 226, reward 14.610, speed 99.98 f/s\n",
            "591851: games 227, reward 14.720, speed 100.55 f/s\n",
            "593847: games 228, reward 14.790, speed 100.14 f/s\n",
            "595898: games 229, reward 14.930, speed 98.57 f/s\n",
            "597783: games 230, reward 15.070, speed 100.00 f/s\n",
            "599551: games 231, reward 15.180, speed 100.30 f/s\n",
            "601300: games 232, reward 15.360, speed 101.40 f/s\n",
            "603074: games 233, reward 15.470, speed 99.82 f/s\n",
            "604962: games 234, reward 15.600, speed 100.20 f/s\n",
            "607008: games 235, reward 15.770, speed 100.55 f/s\n",
            "608776: games 236, reward 15.870, speed 100.82 f/s\n",
            "610700: games 237, reward 15.960, speed 101.98 f/s\n",
            "612701: games 238, reward 16.090, speed 99.38 f/s\n",
            "614605: games 239, reward 16.230, speed 99.86 f/s\n",
            "616760: games 240, reward 16.310, speed 100.07 f/s\n",
            "619320: games 241, reward 16.390, speed 100.81 f/s\n",
            "621679: games 242, reward 16.490, speed 99.53 f/s\n",
            "624021: games 243, reward 16.490, speed 100.03 f/s\n",
            "625815: games 244, reward 16.580, speed 100.54 f/s\n",
            "627968: games 245, reward 16.630, speed 100.11 f/s\n",
            "629714: games 246, reward 16.690, speed 99.48 f/s\n",
            "631444: games 247, reward 16.810, speed 99.23 f/s\n",
            "633255: games 248, reward 16.920, speed 98.84 f/s\n",
            "634987: games 249, reward 17.040, speed 98.77 f/s\n",
            "636653: games 250, reward 17.180, speed 98.87 f/s\n",
            "638620: games 251, reward 17.280, speed 97.49 f/s\n",
            "640346: games 252, reward 17.370, speed 99.46 f/s\n",
            "642042: games 253, reward 17.430, speed 99.62 f/s\n",
            "643694: games 254, reward 17.540, speed 98.27 f/s\n",
            "645505: games 255, reward 17.610, speed 98.64 f/s\n",
            "647254: games 256, reward 17.670, speed 99.59 f/s\n",
            "648980: games 257, reward 17.800, speed 100.46 f/s\n",
            "650633: games 258, reward 17.910, speed 100.84 f/s\n",
            "652286: games 259, reward 17.990, speed 101.22 f/s\n",
            "653939: games 260, reward 18.070, speed 100.72 f/s\n",
            "655664: games 261, reward 18.130, speed 101.88 f/s\n",
            "657316: games 262, reward 18.240, speed 100.67 f/s\n",
            "658967: games 263, reward 18.300, speed 100.53 f/s\n",
            "660618: games 264, reward 18.360, speed 98.54 f/s\n",
            "662269: games 265, reward 18.440, speed 100.86 f/s\n",
            "663921: games 266, reward 18.530, speed 100.20 f/s\n",
            "665573: games 267, reward 18.570, speed 100.31 f/s\n",
            "667224: games 268, reward 18.640, speed 101.66 f/s\n",
            "668875: games 269, reward 18.690, speed 101.97 f/s\n",
            "670580: games 270, reward 18.750, speed 100.70 f/s\n",
            "672315: games 271, reward 18.830, speed 101.76 f/s\n",
            "674072: games 272, reward 18.880, speed 101.63 f/s\n",
            "675769: games 273, reward 18.910, speed 100.89 f/s\n",
            "677421: games 274, reward 19.000, speed 100.68 f/s\n",
            "679171: games 275, reward 19.050, speed 101.34 f/s\n",
            "Solved!\n"
          ]
        }
      ],
      "source": [
        "# === Główna pętla treningowa ===\n",
        "if __name__ == \"__main__\":\n",
        "    import time\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    env = make_env(ENV_NAME)\n",
        "\n",
        "    net = NoisyDQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "    tgt_net = NoisyDQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "    tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "    agent = Agent(env, buffer)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "    best_mean_reward = None\n",
        "    rewards = []\n",
        "    speeds = []\n",
        "    snr_1_list = []\n",
        "    snr_2_list = []\n",
        "    frame_idx = 0\n",
        "    ts = time.time()\n",
        "    ts_frame = 0\n",
        "\n",
        "    while True:\n",
        "        frame_idx += 1\n",
        "        reward = agent.play_step(net, device)\n",
        "        net.reset_noise()\n",
        "\n",
        "        if reward is not None:\n",
        "            rewards.append(reward)\n",
        "            speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "            ts_frame = frame_idx\n",
        "            ts = time.time()\n",
        "            m_reward = np.mean(rewards[-100:])\n",
        "            writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "            writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "            writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "\n",
        "            print(f\"{frame_idx}: games {len(rewards)}, reward {m_reward:.3f}, speed {speed:.2f} f/s\")\n",
        "            if best_mean_reward is None or best_mean_reward < m_reward:\n",
        "                torch.save(net.state_dict(), MODEL_SAVE_PATH)\n",
        "                best_mean_reward = m_reward\n",
        "            if m_reward > MEAN_REWARD_BOUND:\n",
        "                print(\"Solved!\")\n",
        "                break\n",
        "\n",
        "        if len(buffer) < REPLAY_START_SIZE:\n",
        "            continue\n",
        "\n",
        "        if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "            tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "        batch = buffer.sample(BATCH_SIZE)\n",
        "        loss = calc_loss(batch, net, tgt_net, device)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        writer.add_scalar(\"loss\", loss.item(), frame_idx)\n",
        "\n",
        "        # SNR monitoring\n",
        "        snr_1 = (net.fc1.weight_mu.pow(2).mean().sqrt() / net.fc1.weight_sigma.pow(2).mean().sqrt()).item()\n",
        "        snr_2 = (net.fc2.weight_mu.pow(2).mean().sqrt() / net.fc2.weight_sigma.pow(2).mean().sqrt()).item()\n",
        "        writer.add_scalar(\"SNR/layer1\", snr_1, frame_idx)\n",
        "        writer.add_scalar(\"SNR/layer2\", snr_2, frame_idx)\n",
        "        snr_1_list.append(snr_1)\n",
        "        snr_2_list.append(snr_2)\n",
        "\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JLrobp0yIbgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbdd78cc-d197-4a65-e106-656235a5c969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Zapisano nagranie testu agenta do pliku: noisy_dqn_test_run.mp4\n"
          ]
        }
      ],
      "source": [
        "    # === Testowanie i nagrywanie ===\n",
        "    test_env = make_env(ENV_NAME, render_mode=\"rgb_array\")\n",
        "    net.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    net.eval()\n",
        "\n",
        "    video_frames = []\n",
        "    obs, _ = test_env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        obs_v = torch.tensor([obs], device=device)\n",
        "        q_vals = net(obs_v)\n",
        "        action = torch.argmax(q_vals, dim=1).item()\n",
        "        obs, _, terminated, truncated, _ = test_env.step(action)\n",
        "        done = terminated or truncated\n",
        "        frame = test_env.render()\n",
        "        video_frames.append(frame)\n",
        "\n",
        "    with imageio.get_writer(TEST_VIDEO_PATH, fps=30, codec='libx264') as writer:\n",
        "        for frame in video_frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    print(f\"✅ Zapisano nagranie testu agenta do pliku: {TEST_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Wykresy ===\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "\n",
        "log_dir = writer.log_dir if hasattr(writer, 'log_dir') else \"runs\"\n",
        "event_files = []\n",
        "for root, dirs, files in os.walk(log_dir):\n",
        "    for file in files:\n",
        "        if file.startswith(\"events.out.tfevents\"):\n",
        "            event_files.append(os.path.join(root, file))\n",
        "\n",
        "if len(event_files) > 0:\n",
        "    ea = event_accumulator.EventAccumulator(event_files[0])\n",
        "    ea.Reload()\n",
        "\n",
        "    for tag, title, fname in [\n",
        "        (\"reward_100\", \"Średnia nagroda (100 gier)\", \"reward_mean_plot.png\"),\n",
        "        (\"reward\", \"Nagroda\", \"reward_plot.png\"),\n",
        "        (\"speed\", \"Prędkość (klatki/s)\", \"speed_plot.png\"),  # <-- DODANE\n",
        "    ]:\n",
        "        try:\n",
        "            scalars = ea.Scalars(tag)\n",
        "            steps = [s.step for s in scalars]\n",
        "            values = [s.value for s in scalars]\n",
        "            plt.figure(figsize=(12, 5))\n",
        "            plt.plot(steps, values)\n",
        "            plt.xlabel(\"Iteracja\")\n",
        "            plt.ylabel(title)\n",
        "            plt.title(f\"Trening – {title}\")\n",
        "            plt.grid()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(fname)\n",
        "            plt.close()\n",
        "        except KeyError:\n",
        "            print(f\"⚠️ Nie znaleziono danych dla tagu: {tag}\")\n",
        "\n",
        "    # SNR warstwy 1 i 2 na jednym wykresie\n",
        "    try:\n",
        "        snr1 = ea.Scalars(\"SNR/layer1\")\n",
        "        snr2 = ea.Scalars(\"SNR/layer2\")\n",
        "        steps1 = [s.step for s in snr1]\n",
        "        values1 = [s.value for s in snr1]\n",
        "        steps2 = [s.step for s in snr2]\n",
        "        values2 = [s.value for s in snr2]\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.plot(steps1, values1, label=\"SNR warstwa 1\")\n",
        "        plt.plot(steps2, values2, label=\"SNR warstwa 2\")\n",
        "        plt.xlabel(\"Iteracja\")\n",
        "        plt.ylabel(\"SNR\")\n",
        "        plt.title(\"Trening – SNR warstw Noisy DQN\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"snr_plot.png\")\n",
        "        plt.close()\n",
        "    except KeyError:\n",
        "        print(\"⚠️ Nie znaleziono danych SNR dla warstw noisy.\")\n",
        "else:\n",
        "    print(\"⚠️ Brak plików logów TensorBoard do wygenerowania wykresów.\")"
      ],
      "metadata": {
        "id": "AthPNYXO27kB"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOTUObM90Pr8mgvXih7mXC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}